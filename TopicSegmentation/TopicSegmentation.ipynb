{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T07:16:48.393058Z",
     "start_time": "2024-05-21T07:16:48.385862Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff841c5196b7c9ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:20:41.653445Z",
     "start_time": "2024-05-20T15:20:41.600158Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lines=[]\n",
    "with open('VCSum/vcsum_data/overall_context.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "data_context = [json.loads(line.rstrip('\\n')) for line in lines]\n",
    "context_list = [d[\"context\"] for d in data_context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80f944a58c43b149",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:32:48.266488Z",
     "start_time": "2024-05-20T15:32:48.263692Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9835aa98464cc59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:22:13.058117Z",
     "start_time": "2024-05-20T15:22:13.056398Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 24, 32, 43]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_context[0][\"eos_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3aea7fa5633b48a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:35:40.857768Z",
     "start_time": "2024-05-20T15:35:40.856371Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_context[238][\"speaker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45a514aa9f20c3da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:36:05.252673Z",
     "start_time": "2024-05-20T15:36:05.245162Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['我们第一位请是这个陈文林老师非常荣幸，还第一位就是一位女经济学家，是一位女士陈老师是这个中国国际经济交流中心的总经济师，还曾经担任过国务院研究室的司长也是这个商务部的专家，有请陈老师非常荣幸。',\n",
       "  '全球库，智库非常值得赞赏，他们出了很多的专注，组织了很多的活动，尤其是辉耀这个在中美关系世界人物台上，这个苗缕就非常的活跃我特别赞赏。',\n",
       "  '在这个中美关系处在这个困难的时刻，不要和这个美国的著名学者、专家、政客们进行了一系列都是深度的访谈每一个访谈的都不是说像我们这五分钟啥也说不了，都是俩小时三小时，我都那个很多都拜读了，我觉得是非常有水平的，这几句话就不算我的时间了。',\n",
       "  '我觉得现在就是我就想这个世界是平的原来这个全球化过程中有学者指出来世界是平的。',\n",
       "  '后来又有学者说世界是信的其实前一段时间我觉得世界是斜的倾斜负均衡。',\n",
       "  '但是现在世界是乱的，世界百年未有之大变局，处在这个这个急剧的变动和演化之中。',\n",
       "  '所以在这样的一个情况下，这个全球化处于历史的十字路口。'],\n",
       " ['我谈几个观点。',\n",
       "  '第一，人类面临着共同的挑战。',\n",
       "  '正如习主席所指出的，人类还未走出世纪疫情的阴霾，又面为新的传统安全风险，全球经济复苏中脆弱乏力又叠加发展鸿沟加剧的矛盾、气候变化等，治理池子尚未添补，数字治理等新课题又摆在我们面前。',\n",
       "  '那我说世界是乱的，为什么说世界是乱的呢？',\n",
       "  '其实由于这些种种原因，公共卫生危机、能源危机、粮食危机、难免危机、生态危机和金融风险、债务风险、产业链、供应链断链的风险、战争风险交织叠加。',\n",
       "  '四大池子治理池子、信任池子、和平池子、发展池子急剧增长。',\n",
       "  '国际货币基金组织、世界银行、联合国连续下调了对世界经济增长的预期。',\n",
       "  '而且世界银行预测，世界经济将经历发射出现多年以来最大的一个幅度的建减速。',\n",
       "  '全球债务监测报告显示，全球债务总额已经达到三百零三万亿，占全球 GDP 的百分之三百五十一。',\n",
       "  '联合国粮食计划署指出，人类或将面临第二次世界大战后最大的粮食危机，能源危机多达 17 亿人，正暴露在粮食、能源和金融系统的破坏之下。'],\n",
       " ['第二个观点就是我们的人类各个国家面临着共同的考试，其实对于考试题有很多。',\n",
       "  '但是现在我觉得可能对于全球化来说，对于全球经济来说，面临的这些考题集中在几个方面。',\n",
       "  '第一，世界到底能不能一分为二一分为三一分为四或者成为碎片化的状态？',\n",
       "  '那如果出现这种情况，世界的前生命运将是怎样一幅愿景？',\n",
       "  '实际上现在我们还是也是全球经济还是一体化这个格局，总的这个状态没有打破。',\n",
       "  '那么如果像一些政客推进的这些去宣传化去中国化或者是搞这个两套体系。'],\n",
       " ['那么世界会选择什么样？',\n",
       "  '第二，世界经济能不能没有稳定之矛绑购？',\n",
       "  '世界经济增长的稳定之矛，货币体系的稳定之矛，大宗商品价格的稳定之矛，产业链供应链的稳定之矛如何摒弃脱钩断供、单边制裁、极限施压贸易壁垒全球产业链供应链断链小院方高强这些能找到根本解决之道到底有没有稳定之矛？',\n",
       "  '第三，世界的大国之间究竟应该怎样相处？',\n",
       "  '什么是真正的多边主义？',\n",
       "  '是构建人类命运共同体？',\n",
       "  '还是把一个国家的利益置于其他国家和全球利益之上？',\n",
       "  '是遵守国际秩序国际规则间，还是把加法和方规变成打压遏制制裁其他国家的工具。'],\n",
       " ['那么这个第四就是如何避免发生冲突和局部战争，对战后几十年的二百多场战争如何评价？',\n",
       "  '那么如何定义现代战争啊？',\n",
       "  '那么现在战争是不是只是战场上的战争？',\n",
       "  '那么生物战、经济、标准规则之战、货币战、信息站、网络站、舆论站。',\n",
       "  '那么和现代战争它怎么成为一个一体化的新型战争如何解决当前的俄乌冲突？',\n",
       "  '如何避免新冷战和第三次世界大战和第三次世界大战。',\n",
       "  '那么第五这是第几了，说错了一二三四第五就是如何建立有利于全球降低四大池子的国际秩序与国际规则，构建保持全球数据和平稳健均衡发展安全整体的这样的环境。',\n",
       "  '那么第六如何构建全球公共品的供给体系。'],\n",
       " ['那么新型的全球公共品它的概念定义内涵是什么？',\n",
       "  '和过去霸权国家主宰下的公共品究竟有什么不同？',\n",
       "  '那么再一个我觉得在当前如何进行全球宏观经济政策的沟通和协调，怎样赋予并充分发挥联合国、世界银行 AI 还复杂不出等国际组织进行全球政策沟通协调的这个功能。'],\n",
       " ['例如美国加息现在是政策急转弯。',\n",
       "  '到目前为止，已经跟进美国加息的国家包括美国在内，那么它的这个经济总量已经占到全球 GDP 的60.6%，',\n",
       "  '进口总量占了全球进口市场的42.2%。',\n",
       "  '所以世界银行对这些家期跟进的国家进行了评估，就是他们的 2022 年民营 GDP 增速将比 2021 年减少 4.2 ',\n",
       "  '个百分点，损失 GDP 达到 2.42 ',\n",
       "  '万亿美元，损失消费额 1.69 ',\n",
       "  '万亿美元，这将导致全球 GDP 增速下降2.55，',\n",
       "  '导致全球出口减少百分之七点五一，而且还会导致一大批发展中国家自己短缺。',\n",
       "  '美元荒货币大幅度贬值。',\n",
       "  '那么经济发展严重受到严重重创。',\n",
       "  '所以现在一系列的这个非常严峻的，就大家不得不回答这些问题，就摆在我们的面前，实际上这也关乎到经济权益化的一个命运，人类发生的命运。'],\n",
       " ['第三个这个观点就是共同的不同的出路和选择。',\n",
       "  ' 4 月 20 号在国外论坛会议上，习主席讲话，世界各国创作的一条命令，与共的大船上要穿越镜头排浪驶向光明，未来必须从舟共济，企图把谁扔下大海都是不可接受的。',\n",
       "  '那么在最近习主席在 76 届这个联合联会上，就是去年习主席讲国际社会发展的今天已经成为一部复杂精巧、有机一体的机器，拆掉一个零部件就会使整个机器运转面临严重困难，被拆的人会受损，拆的人也会受损。',\n",
       "  '那么战后到现在 77 年已经形成了世界经济的金融格局。',\n",
       "  '地缘政治经济的基本国籍和世界各国认同的秩序、国际规则和国际经济运行的这些制度性安排。',\n",
       "  '那么全球的投资贸易布局、产业链、供应链布局、互联网、物联网、空中导航系统、人工智能下一代数字基础设施和高科技的运动发展都是为了互联，都是为了造福于人类。'],\n",
       " ['那么都是，它的背自然结果都会是全球的经济，社会联系越来越紧密，而不是脱钩分裂对抗阻断重构。',\n",
       "  '那么如果如果现在执意要推动这些这个一些政客出于去中国化也好，孤立其他国家也好。',\n",
       "  '那么这些行为我觉得最后会受到反噬。',\n",
       "  '那么建立全球化不仅会遭遇逆流，而且这一些阻断经济全球化的遏制经济全球化的对冲经济全球化的这一系列的行为。',\n",
       "  '也不管什么团体，也不管什么名头，我觉得最后都会受到历史的惩罚和抛弃。',\n",
       "  '谢谢。']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_context[238][\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe8445355037312",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "[\"\".join(c) for c in data_context[0][\"context\"][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "520da627b88e758a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:21:57.975469Z",
     "start_time": "2024-05-20T15:21:57.967226Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_context[0][\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bff5823285219085",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:30:33.910776Z",
     "start_time": "2024-05-20T15:30:33.907820Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215, 138, 17480)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_val = 0\n",
    "count = 0\n",
    "num = 0\n",
    "for i in range(len(data_context)):\n",
    "    for context in data_context[i][\"context\"]:\n",
    "        num +=1\n",
    "        val = len(context)\n",
    "        if val > 15:\n",
    "            count += 1\n",
    "        max_val = max(max_val,val)\n",
    "max_val,count,num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1a9e9c5d3819b71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T07:16:56.663070Z",
     "start_time": "2024-05-21T07:16:56.650726Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lines=[]\n",
    "with open('/Users/dingyi/Downloads/CityU/Project/MeetingSummarization/TopicSegmentation/data/5/sg_5_short_test.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "data_context = [json.loads(line.rstrip('\\n')) for line in lines]\n",
    "# context_list = [d[\"context\"] for d in data_context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79261919417b595a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T07:16:57.702588Z",
     "start_time": "2024-05-21T07:16:57.696301Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "example = data_context[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7308ba1fff2066f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T07:19:35.390023Z",
     "start_time": "2024-05-21T07:19:35.384601Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['好下各位下午好。', '临时科技我们是一家做安全的公司，可能跟各位的还有点不太一样。', '然后我们主要是给各种交易所，然后公链合约还有钱包等做安全审计的，包括今天的嘉宾，雷神公链，还有科特米尔公链都是我们的合作伙伴。', '然后大家可能只需要记，就是说后续有项目方或者交易所需要做安全审计的，比如说合约审计的或者是用户数字资产丢失了，有什么安全响应的事件可以找我们，我们是要做安全的企业。', '谢谢。']\n",
      "['好下各位下午好。', '临时科技我们是一家做安全的公司，可能跟各位的还有点不太一样。', '然后我们主要是给各种交易所，然后公链合约还有钱包等做安全审计的，包括今天的嘉宾，雷神公链，还有科特米尔公链都是我们的合作伙伴。', '然后大家可能只需要记，就是说后续有项目方或者交易所需要做安全审计的，比如说合约审计的或者是用户数字资产丢失了，有什么安全响应的事件可以找我们，我们是要做安全的企业。', '谢谢。']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(example[\"context\"])):\n",
    "    print(i)\n",
    "    print(example[\"context\"][i])\n",
    "    if example[\"context\"][i] is not None and example[\"eos_pos\"][i] is not None:\n",
    "        print([\"\".join(c) for c in example[\"context\"][i]])\n",
    "        break\n",
    "    break\n",
    "            # text_outputs = tokenizer(\n",
    "            #     [\"\".join(c) for c in example[\"context\"][i]],\n",
    "            #     add_special_tokens=False,\n",
    "            #     truncation=False,\n",
    "            # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f54300-e349-4ff4-95b5-77be857a95e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/test/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from datasets import load_dataset, set_caching_enabled\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizerFast,\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from seg_utils import ModelArguments, DataTrainingArguments\n",
    "\n",
    "from modeling_bart import BartForEncoderCls\n",
    "from modeling_bert import BertForEncoderCls\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from data_collator import DataCollatorForTokenClassification\n",
    "from datasets.utils.download_manager import DownloadMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0885e4e0-eed4-4b30-9a5f-a24784fef34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "set_caching_enabled(True)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "925e1845-ab0c-4ec4-8509-84b4061b9416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(example, tokenizer, max_length=256):\n",
    "\n",
    "    inputs, attention_mask, position_ids, token_type_ids = [], [], [], []\n",
    "    eos_ids, eos_attention_mask = [], []\n",
    "    labels = []\n",
    "    for i in range(len(example[\"context\"])):\n",
    "        if example[\"context\"][i] is not None and example[\"eos_pos\"][i] is not None:\n",
    "            text_outputs = tokenizer(\n",
    "                [\"\".join(c) for c in example[\"context\"][i]],\n",
    "                add_special_tokens=False,\n",
    "                truncation=False,\n",
    "            )\n",
    "            text_input_ids = text_outputs[\"input_ids\"]\n",
    "            _tmp_input_ids, _tmp_position_ids, _tmp_eos_pos_ids, _tmp_token_type_ids = [], [], [], []\n",
    "            input_ids_length = []\n",
    "            for idx, text in enumerate(text_input_ids):\n",
    "                if len(text) > max_length:\n",
    "                    # text = text[:int(max_length//2)] + text[-int(max_length//2):]\n",
    "                    text = text[-int(max_length-1):]\n",
    "                text.insert(0, tokenizer.cls_token_id)\n",
    "                _tmp_input_ids.extend(text)\n",
    "                _tmp_token_type_ids.extend([idx % 2] * len(text))\n",
    "                input_ids_length.append(len(text))\n",
    "            total_length = sum(input_ids_length)\n",
    "            _tmp_attention_mask = [1] * total_length\n",
    "            acc_len = 0\n",
    "            for cur_len in input_ids_length:\n",
    "                # _tmp_mask = [0] * acc_len + [1] * cur_len + [0] * (total_length - acc_len - cur_len)\n",
    "                # _tmp_mask = [1] * total_length\n",
    "                # _tmp_attention_mask.extend([_tmp_mask] * cur_len)\n",
    "                _tmp_position_ids.extend(list(range(acc_len, acc_len + cur_len)))\n",
    "                acc_len += cur_len\n",
    "                _tmp_eos_pos_ids.append(acc_len - 1)\n",
    "            attention_mask.append(_tmp_attention_mask)\n",
    "            inputs.append(_tmp_input_ids)\n",
    "            position_ids.append(_tmp_position_ids)\n",
    "            eos_ids.append(_tmp_eos_pos_ids)\n",
    "            token_type_ids.append(_tmp_token_type_ids)\n",
    "            utt_num = len(example[\"context\"][i])\n",
    "            eos_attention_mask.append([1 for _ in range(utt_num)])\n",
    "            labels.append([int(_ in example[\"eos_pos\"][i]) for _ in range(utt_num)])\n",
    "\n",
    "    model_inputs = {\n",
    "        \"input_ids\": inputs,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"position_ids\": position_ids,\n",
    "        \"token_type_ids\": token_type_ids,\n",
    "        \"eos_ids\": eos_ids,\n",
    "        \"eos_attention_mask\": eos_attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c0be04-627d-4f8e-bbd5-b2de5a5c1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # See all possible arguments in src/transformers/training_args.py\n",
    "    # or by passing the --help flag to this script.\n",
    "    # We now keep distinct sets of args, for a cleaner separation of concerns.\n",
    "    # 解析模型参数,数据参数,训练参数\n",
    "    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "    if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "        # If we pass only one argument to the script and it's the path to a json file,\n",
    "        # let's parse it to get our arguments.\n",
    "        model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n",
    "    else:\n",
    "        model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n",
    "    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n",
    "    # 设置日志\n",
    "    # Setup logging\n",
    "    logging.basicConfig(\n",
    "        format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "        datefmt='%m/%d/%Y %H:%M:%S',\n",
    "        level=logging.INFO)\n",
    "\n",
    "    # Log on each process the small summary:\n",
    "    logger.warning(\n",
    "        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    "    )\n",
    "    logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "\n",
    "    # 设置输出 checkpoint\n",
    "    # Detecting last checkpoint.\n",
    "    last_checkpoint = None\n",
    "    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n",
    "        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "            raise ValueError(\n",
    "                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "                \"Use --overwrite_output_dir to overcome.\"\n",
    "            )\n",
    "        elif last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n",
    "            logger.info(\n",
    "                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "            )\n",
    "\n",
    "    # Set seed before initializing model.\n",
    "    seed = training_args.seed + training_args.local_rank\n",
    "    set_seed(seed)\n",
    "\n",
    "    # 加载数据集\n",
    "    # In distributed training, the load_dataset function guarantee that only one local process can concurrently\n",
    "    # download the dataset.\n",
    "    if data_args.dataset_name is not None:\n",
    "        # Downloading and loading a dataset from the hub.\n",
    "        raw_datasets = load_dataset(\n",
    "            data_args.dataset_name,\n",
    "            data_args.dataset_config_name,\n",
    "            cache_dir=model_args.cache_dir,\n",
    "            use_auth_token=True if model_args.use_auth_token else None,\n",
    "        )\n",
    "    else:\n",
    "        data_files = {}\n",
    "        if data_args.train_file is not None:\n",
    "            data_files[\"train\"] = data_args.train_file\n",
    "        if data_args.validation_file is not None:\n",
    "            data_files[\"validation\"] = data_args.validation_file\n",
    "        if data_args.test_file is not None:\n",
    "            data_files[\"test\"] = data_args.test_file\n",
    "        raw_datasets = load_dataset(\n",
    "            \"json\",\n",
    "            data_files=data_files,\n",
    "            cache_dir=model_args.cache_dir,\n",
    "            download_mode=DownloadMode.FORCE_REDOWNLOAD,\n",
    "            use_auth_token=True if model_args.use_auth_token else None,\n",
    "        )\n",
    "    # See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at\n",
    "    # https://huggingface.co/docs/datasets/loading_datasets.html.\n",
    "\n",
    "    # Load pretrained model and tokenizer\n",
    "    #\n",
    "    # Distributed training:\n",
    "    # The .from_pretrained methods guarantee that only one local process can concurrently\n",
    "    # download model & vocab.\n",
    "\n",
    "    # 加载模型(BARTenc, BERTenc),tokenizer\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(\n",
    "        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "        use_fast=model_args.use_fast_tokenizer,\n",
    "    )\n",
    "    if \"bart\" in model_args.model_name_or_path.lower():\n",
    "        model = BartForEncoderCls.from_pretrained(model_args.model_name_or_path,\n",
    "                                                  num_labels=2,\n",
    "                                                  ignore_mismatched_sizes=True,\n",
    "                                                  max_position_embeddings=max(512, model_args.turn_num * model_args.max_utterance_length),\n",
    "                                                  use_focal_loss=model_args.loss_fct == \"focal\")\n",
    "    elif \"bert\" in model_args.model_name_or_path.lower():\n",
    "        model = BertForEncoderCls.from_pretrained(model_args.model_name_or_path,\n",
    "                                                  num_labels=2,\n",
    "                                                  max_position_embeddings=max(512, 10 * model_args.max_utterance_length),\n",
    "                                                  use_focal_loss=model_args.use_focal_loss,\n",
    "                                                  ignore_mismatched_sizes=True)\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected model.\")\n",
    "    # else:\n",
    "    #     model = BertForTokenClassification.from_pretrained(model_args.model_name_or_path, num_labels=2)\n",
    "\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    # 训练\n",
    "    if training_args.do_train:\n",
    "        if \"train\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_train requires a train dataset\")\n",
    "        train_dataset = raw_datasets[\"train\"]\n",
    "        if data_args.max_train_samples is not None:\n",
    "            max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n",
    "            train_dataset = train_dataset.select(range(max_train_samples))\n",
    "        with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n",
    "            train_dataset = train_dataset.map(\n",
    "                preprocess_function,\n",
    "                batched=True,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                remove_columns=raw_datasets[\"train\"].column_names,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                # cache_file_name=f\"{data_args.train_file}\".replace(\"txt\", \"arrow\"),\n",
    "                fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": model_args.max_utterance_length},\n",
    "                desc=\"Running tokenizer on train dataset\",\n",
    "            )\n",
    "\n",
    "    # 评估\n",
    "    if training_args.do_eval:\n",
    "        # max_target_length = data_args.val_max_target_length\n",
    "        if \"validation\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_eval requires a validation dataset\")\n",
    "        eval_dataset = raw_datasets[\"validation\"]\n",
    "        if data_args.max_eval_samples is not None:\n",
    "            max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n",
    "            eval_dataset = eval_dataset.select(range(max_eval_samples))\n",
    "        with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n",
    "            eval_dataset = eval_dataset.map(\n",
    "                preprocess_function,\n",
    "                batched=True,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                remove_columns=raw_datasets[\"validation\"].column_names,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                # cache_file_name=f\"{data_args.train_file}\".replace(\"txt\", \"arrow\"),\n",
    "                fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": model_args.max_utterance_length},\n",
    "                desc=\"Running tokenizer on validation dataset\",\n",
    "            )\n",
    "\n",
    "    # 预测\n",
    "    if training_args.do_predict:\n",
    "        # max_target_length = data_args.val_max_target_length\n",
    "        if \"test\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_predict requires a test dataset\")\n",
    "        predict_dataset = raw_datasets[\"test\"]\n",
    "        if data_args.max_predict_samples is not None:\n",
    "            max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\n",
    "            predict_dataset = predict_dataset.select(range(max_predict_samples))\n",
    "        with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\n",
    "            predict_dataset = predict_dataset.map(\n",
    "                preprocess_function,\n",
    "                batched=True,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                remove_columns=raw_datasets[\"test\"].column_names,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                # cache_file_name=f\"{data_args.train_file}\".replace(\"txt\", \"arrow\"),\n",
    "                fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": model_args.max_utterance_length},\n",
    "                desc=\"Running tokenizer on prediction dataset\",\n",
    "            )\n",
    "\n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForTokenClassification(\n",
    "        tokenizer=tokenizer,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    def compute_metrics(eval_preds):\n",
    "        preds, labels = eval_preds\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "        predictions = np.argmax(preds, axis=-1)\n",
    "        f_scores = []\n",
    "        for i in range(predictions.shape[0]):\n",
    "            pred = np.extract(labels[i] >= 0, predictions[i])\n",
    "            label = np.extract(labels[i] >= 0, labels[i])\n",
    "            equ_num = sum(pred == label)\n",
    "            pred_len = sum(pred >= 0)\n",
    "            label_len = sum(label >= 0)\n",
    "            p = equ_num / pred_len if pred_len > 0 else 0\n",
    "            r = equ_num / label_len if label_len > 0 else 0\n",
    "            f = 2 * p * r / (p + r) if p + r > 0 else 0\n",
    "            f_scores.append(f)\n",
    "            # pred = [str(_) for _ in predictions[i].tolist()]\n",
    "            # label = [str(_) for _ in labels[i].tolist() if _ >= 0]\n",
    "            # pred = pred[:len(label)]\n",
    "            # wd_scores.append(windowdiff(\"\".join(pred), \"\".join(label), k=1))\n",
    "        # print(\n",
    "        #     f\"pred: {predictions}\\nlabel: {labels}\"\n",
    "        # )\n",
    "        res = {\"f\": sum(f_scores)/len(f_scores)}\n",
    "        return res\n",
    "\n",
    "    # Initialize our Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset if training_args.do_train else None,\n",
    "        eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    if training_args.do_train:\n",
    "        checkpoint = None\n",
    "        if training_args.resume_from_checkpoint is not None:\n",
    "            checkpoint = training_args.resume_from_checkpoint\n",
    "        elif last_checkpoint is not None:\n",
    "            checkpoint = last_checkpoint\n",
    "        trainer.train(resume_from_checkpoint=checkpoint)\n",
    "        trainer.save_model(f\"{training_args.output_dir}/best_model\")  # Saves the tokenizer too for easy upload\n",
    "\n",
    "    if training_args.do_predict:\n",
    "        logger.info(\"*** Predict ***\")\n",
    "\n",
    "        predict_results = trainer.predict(\n",
    "            predict_dataset, metric_key_prefix=\"predict\"\n",
    "        )\n",
    "        metrics = predict_results.metrics\n",
    "        logger.info(metrics)\n",
    "        if trainer.is_world_process_zero():\n",
    "            output_prediction_file = os.path.join(\n",
    "                training_args.output_dir, f\"{model_args.model_name_or_path.replace('/', '_')}_res.txt\")\n",
    "            predictions = predict_results.predictions[0]\n",
    "            labels = predict_results.label_ids\n",
    "\n",
    "            with open(output_prediction_file, \"w\", encoding=\"utf-8\") as fw:\n",
    "                for pred, label in zip(predictions, labels):\n",
    "                    pred = np.argmax(pred, axis=-1)\n",
    "                    fw.write(json.dumps({\"pred\": pred.tolist(), \"label\": label.tolist()}, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a7d6cf5-7048-4e7d-a168-2c53624aef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --model_name_or_path MODEL_NAME_OR_PATH\n",
      "                             [--config_name CONFIG_NAME]\n",
      "                             [--tokenizer_name TOKENIZER_NAME]\n",
      "                             [--cache_dir CACHE_DIR]\n",
      "                             [--use_fast_tokenizer [USE_FAST_TOKENIZER]]\n",
      "                             [--no_use_fast_tokenizer]\n",
      "                             [--model_revision MODEL_REVISION]\n",
      "                             [--use_auth_token [USE_AUTH_TOKEN]]\n",
      "                             [--max_utterance_length MAX_UTTERANCE_LENGTH]\n",
      "                             [--loss_fct LOSS_FCT] [--turn_num TURN_NUM]\n",
      "                             [--lang LANG] [--train_file TRAIN_FILE]\n",
      "                             [--validation_file VALIDATION_FILE]\n",
      "                             [--test_file TEST_FILE]\n",
      "                             [--overwrite_cache [OVERWRITE_CACHE]]\n",
      "                             [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]\n",
      "                             [--pad_to_max_length [PAD_TO_MAX_LENGTH]]\n",
      "                             [--max_train_samples MAX_TRAIN_SAMPLES]\n",
      "                             [--max_eval_samples MAX_EVAL_SAMPLES]\n",
      "                             [--max_predict_samples MAX_PREDICT_SAMPLES]\n",
      "                             [--source_prefix SOURCE_PREFIX]\n",
      "                             [--forced_bos_token FORCED_BOS_TOKEN]\n",
      "                             [--dataset_name DATASET_NAME]\n",
      "                             [--dataset_config_name DATASET_CONFIG_NAME]\n",
      "                             --output_dir OUTPUT_DIR\n",
      "                             [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]\n",
      "                             [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]\n",
      "                             [--do_predict [DO_PREDICT]]\n",
      "                             [--eval_strategy {no,steps,epoch}]\n",
      "                             [--prediction_loss_only [PREDICTION_LOSS_ONLY]]\n",
      "                             [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
      "                             [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
      "                             [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
      "                             [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n",
      "                             [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                             [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]\n",
      "                             [--eval_delay EVAL_DELAY]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--weight_decay WEIGHT_DECAY]\n",
      "                             [--adam_beta1 ADAM_BETA1]\n",
      "                             [--adam_beta2 ADAM_BETA2]\n",
      "                             [--adam_epsilon ADAM_EPSILON]\n",
      "                             [--max_grad_norm MAX_GRAD_NORM]\n",
      "                             [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                             [--max_steps MAX_STEPS]\n",
      "                             [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]\n",
      "                             [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]\n",
      "                             [--warmup_ratio WARMUP_RATIO]\n",
      "                             [--warmup_steps WARMUP_STEPS]\n",
      "                             [--log_level {detail,debug,info,warning,error,critical,passive}]\n",
      "                             [--log_level_replica {detail,debug,info,warning,error,critical,passive}]\n",
      "                             [--log_on_each_node [LOG_ON_EACH_NODE]]\n",
      "                             [--no_log_on_each_node]\n",
      "                             [--logging_dir LOGGING_DIR]\n",
      "                             [--logging_strategy {no,steps,epoch}]\n",
      "                             [--logging_first_step [LOGGING_FIRST_STEP]]\n",
      "                             [--logging_steps LOGGING_STEPS]\n",
      "                             [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]\n",
      "                             [--no_logging_nan_inf_filter]\n",
      "                             [--save_strategy {no,steps,epoch}]\n",
      "                             [--save_steps SAVE_STEPS]\n",
      "                             [--save_total_limit SAVE_TOTAL_LIMIT]\n",
      "                             [--save_safetensors [SAVE_SAFETENSORS]]\n",
      "                             [--no_save_safetensors]\n",
      "                             [--save_on_each_node [SAVE_ON_EACH_NODE]]\n",
      "                             [--save_only_model [SAVE_ONLY_MODEL]]\n",
      "                             [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]\n",
      "                             [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]\n",
      "                             [--use_mps_device [USE_MPS_DEVICE]] [--seed SEED]\n",
      "                             [--data_seed DATA_SEED]\n",
      "                             [--jit_mode_eval [JIT_MODE_EVAL]]\n",
      "                             [--use_ipex [USE_IPEX]] [--bf16 [BF16]]\n",
      "                             [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]\n",
      "                             [--half_precision_backend {auto,apex,cpu_amp}]\n",
      "                             [--bf16_full_eval [BF16_FULL_EVAL]]\n",
      "                             [--fp16_full_eval [FP16_FULL_EVAL]] [--tf32 TF32]\n",
      "                             [--local_rank LOCAL_RANK]\n",
      "                             [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl}]\n",
      "                             [--tpu_num_cores TPU_NUM_CORES]\n",
      "                             [--tpu_metrics_debug [TPU_METRICS_DEBUG]]\n",
      "                             [--debug DEBUG [DEBUG ...]]\n",
      "                             [--dataloader_drop_last [DATALOADER_DROP_LAST]]\n",
      "                             [--eval_steps EVAL_STEPS]\n",
      "                             [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                             [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]\n",
      "                             [--past_index PAST_INDEX] [--run_name RUN_NAME]\n",
      "                             [--disable_tqdm DISABLE_TQDM]\n",
      "                             [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]\n",
      "                             [--no_remove_unused_columns]\n",
      "                             [--label_names LABEL_NAMES [LABEL_NAMES ...]]\n",
      "                             [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]\n",
      "                             [--metric_for_best_model METRIC_FOR_BEST_MODEL]\n",
      "                             [--greater_is_better GREATER_IS_BETTER]\n",
      "                             [--ignore_data_skip [IGNORE_DATA_SKIP]]\n",
      "                             [--fsdp FSDP]\n",
      "                             [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]\n",
      "                             [--fsdp_config FSDP_CONFIG]\n",
      "                             [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]\n",
      "                             [--accelerator_config ACCELERATOR_CONFIG]\n",
      "                             [--deepspeed DEEPSPEED]\n",
      "                             [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]\n",
      "                             [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise}]\n",
      "                             [--optim_args OPTIM_ARGS]\n",
      "                             [--adafactor [ADAFACTOR]]\n",
      "                             [--group_by_length [GROUP_BY_LENGTH]]\n",
      "                             [--length_column_name LENGTH_COLUMN_NAME]\n",
      "                             [--report_to REPORT_TO]\n",
      "                             [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]\n",
      "                             [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]\n",
      "                             [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]\n",
      "                             [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]\n",
      "                             [--no_dataloader_pin_memory]\n",
      "                             [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]\n",
      "                             [--skip_memory_metrics [SKIP_MEMORY_METRICS]]\n",
      "                             [--no_skip_memory_metrics]\n",
      "                             [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]\n",
      "                             [--push_to_hub [PUSH_TO_HUB]]\n",
      "                             [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                             [--hub_model_id HUB_MODEL_ID]\n",
      "                             [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]\n",
      "                             [--hub_token HUB_TOKEN]\n",
      "                             [--hub_private_repo [HUB_PRIVATE_REPO]]\n",
      "                             [--hub_always_push [HUB_ALWAYS_PUSH]]\n",
      "                             [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]\n",
      "                             [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]\n",
      "                             [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]\n",
      "                             [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]\n",
      "                             [--no_eval_do_concat_batches]\n",
      "                             [--fp16_backend {auto,apex,cpu_amp}]\n",
      "                             [--evaluation_strategy {no,steps,epoch}]\n",
      "                             [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]\n",
      "                             [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]\n",
      "                             [--push_to_hub_token PUSH_TO_HUB_TOKEN]\n",
      "                             [--mp_parameters MP_PARAMETERS]\n",
      "                             [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]\n",
      "                             [--full_determinism [FULL_DETERMINISM]]\n",
      "                             [--torchdynamo TORCHDYNAMO]\n",
      "                             [--ray_scope RAY_SCOPE]\n",
      "                             [--ddp_timeout DDP_TIMEOUT]\n",
      "                             [--torch_compile [TORCH_COMPILE]]\n",
      "                             [--torch_compile_backend TORCH_COMPILE_BACKEND]\n",
      "                             [--torch_compile_mode TORCH_COMPILE_MODE]\n",
      "                             [--dispatch_batches DISPATCH_BATCHES]\n",
      "                             [--split_batches SPLIT_BATCHES]\n",
      "                             [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]\n",
      "                             [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]\n",
      "                             [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]\n",
      "                             [--optim_target_modules OPTIM_TARGET_MODULES]\n",
      "                             [--batch_eval_metrics [BATCH_EVAL_METRICS]]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --model_name_or_path, --output_dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb84e59b-0fd4-4f86-9d3c-f1880dc6b6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
