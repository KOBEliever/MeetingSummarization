{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-21T07:16:48.393058Z",
     "start_time": "2024-05-21T07:16:48.385862Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "lines=[]\n",
    "with open('VCSum/vcsum_data/overall_context.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "data_context = [json.loads(line.rstrip('\\n')) for line in lines]\n",
    "context_list = [d[\"context\"] for d in data_context]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T15:20:41.653445Z",
     "start_time": "2024-05-20T15:20:41.600158Z"
    }
   },
   "id": "ff841c5196b7c9ea"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "239"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_context)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T15:32:48.266488Z",
     "start_time": "2024-05-20T15:32:48.263692Z"
    }
   },
   "id": "80f944a58c43b149"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[11, 24, 32, 43]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_context[0][\"eos_index\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T15:22:13.058117Z",
     "start_time": "2024-05-20T15:22:13.056398Z"
    }
   },
   "id": "a9835aa98464cc59"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 1, 1, 1, 1, 1, 1, 1, 1]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_context[238][\"speaker\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T15:35:40.857768Z",
     "start_time": "2024-05-20T15:35:40.856371Z"
    }
   },
   "id": "b3aea7fa5633b48a"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "[['我们第一位请是这个陈文林老师非常荣幸，还第一位就是一位女经济学家，是一位女士陈老师是这个中国国际经济交流中心的总经济师，还曾经担任过国务院研究室的司长也是这个商务部的专家，有请陈老师非常荣幸。',\n  '全球库，智库非常值得赞赏，他们出了很多的专注，组织了很多的活动，尤其是辉耀这个在中美关系世界人物台上，这个苗缕就非常的活跃我特别赞赏。',\n  '在这个中美关系处在这个困难的时刻，不要和这个美国的著名学者、专家、政客们进行了一系列都是深度的访谈每一个访谈的都不是说像我们这五分钟啥也说不了，都是俩小时三小时，我都那个很多都拜读了，我觉得是非常有水平的，这几句话就不算我的时间了。',\n  '我觉得现在就是我就想这个世界是平的原来这个全球化过程中有学者指出来世界是平的。',\n  '后来又有学者说世界是信的其实前一段时间我觉得世界是斜的倾斜负均衡。',\n  '但是现在世界是乱的，世界百年未有之大变局，处在这个这个急剧的变动和演化之中。',\n  '所以在这样的一个情况下，这个全球化处于历史的十字路口。'],\n ['我谈几个观点。',\n  '第一，人类面临着共同的挑战。',\n  '正如习主席所指出的，人类还未走出世纪疫情的阴霾，又面为新的传统安全风险，全球经济复苏中脆弱乏力又叠加发展鸿沟加剧的矛盾、气候变化等，治理池子尚未添补，数字治理等新课题又摆在我们面前。',\n  '那我说世界是乱的，为什么说世界是乱的呢？',\n  '其实由于这些种种原因，公共卫生危机、能源危机、粮食危机、难免危机、生态危机和金融风险、债务风险、产业链、供应链断链的风险、战争风险交织叠加。',\n  '四大池子治理池子、信任池子、和平池子、发展池子急剧增长。',\n  '国际货币基金组织、世界银行、联合国连续下调了对世界经济增长的预期。',\n  '而且世界银行预测，世界经济将经历发射出现多年以来最大的一个幅度的建减速。',\n  '全球债务监测报告显示，全球债务总额已经达到三百零三万亿，占全球 GDP 的百分之三百五十一。',\n  '联合国粮食计划署指出，人类或将面临第二次世界大战后最大的粮食危机，能源危机多达 17 亿人，正暴露在粮食、能源和金融系统的破坏之下。'],\n ['第二个观点就是我们的人类各个国家面临着共同的考试，其实对于考试题有很多。',\n  '但是现在我觉得可能对于全球化来说，对于全球经济来说，面临的这些考题集中在几个方面。',\n  '第一，世界到底能不能一分为二一分为三一分为四或者成为碎片化的状态？',\n  '那如果出现这种情况，世界的前生命运将是怎样一幅愿景？',\n  '实际上现在我们还是也是全球经济还是一体化这个格局，总的这个状态没有打破。',\n  '那么如果像一些政客推进的这些去宣传化去中国化或者是搞这个两套体系。'],\n ['那么世界会选择什么样？',\n  '第二，世界经济能不能没有稳定之矛绑购？',\n  '世界经济增长的稳定之矛，货币体系的稳定之矛，大宗商品价格的稳定之矛，产业链供应链的稳定之矛如何摒弃脱钩断供、单边制裁、极限施压贸易壁垒全球产业链供应链断链小院方高强这些能找到根本解决之道到底有没有稳定之矛？',\n  '第三，世界的大国之间究竟应该怎样相处？',\n  '什么是真正的多边主义？',\n  '是构建人类命运共同体？',\n  '还是把一个国家的利益置于其他国家和全球利益之上？',\n  '是遵守国际秩序国际规则间，还是把加法和方规变成打压遏制制裁其他国家的工具。'],\n ['那么这个第四就是如何避免发生冲突和局部战争，对战后几十年的二百多场战争如何评价？',\n  '那么如何定义现代战争啊？',\n  '那么现在战争是不是只是战场上的战争？',\n  '那么生物战、经济、标准规则之战、货币战、信息站、网络站、舆论站。',\n  '那么和现代战争它怎么成为一个一体化的新型战争如何解决当前的俄乌冲突？',\n  '如何避免新冷战和第三次世界大战和第三次世界大战。',\n  '那么第五这是第几了，说错了一二三四第五就是如何建立有利于全球降低四大池子的国际秩序与国际规则，构建保持全球数据和平稳健均衡发展安全整体的这样的环境。',\n  '那么第六如何构建全球公共品的供给体系。'],\n ['那么新型的全球公共品它的概念定义内涵是什么？',\n  '和过去霸权国家主宰下的公共品究竟有什么不同？',\n  '那么再一个我觉得在当前如何进行全球宏观经济政策的沟通和协调，怎样赋予并充分发挥联合国、世界银行 AI 还复杂不出等国际组织进行全球政策沟通协调的这个功能。'],\n ['例如美国加息现在是政策急转弯。',\n  '到目前为止，已经跟进美国加息的国家包括美国在内，那么它的这个经济总量已经占到全球 GDP 的60.6%，',\n  '进口总量占了全球进口市场的42.2%。',\n  '所以世界银行对这些家期跟进的国家进行了评估，就是他们的 2022 年民营 GDP 增速将比 2021 年减少 4.2 ',\n  '个百分点，损失 GDP 达到 2.42 ',\n  '万亿美元，损失消费额 1.69 ',\n  '万亿美元，这将导致全球 GDP 增速下降2.55，',\n  '导致全球出口减少百分之七点五一，而且还会导致一大批发展中国家自己短缺。',\n  '美元荒货币大幅度贬值。',\n  '那么经济发展严重受到严重重创。',\n  '所以现在一系列的这个非常严峻的，就大家不得不回答这些问题，就摆在我们的面前，实际上这也关乎到经济权益化的一个命运，人类发生的命运。'],\n ['第三个这个观点就是共同的不同的出路和选择。',\n  ' 4 月 20 号在国外论坛会议上，习主席讲话，世界各国创作的一条命令，与共的大船上要穿越镜头排浪驶向光明，未来必须从舟共济，企图把谁扔下大海都是不可接受的。',\n  '那么在最近习主席在 76 届这个联合联会上，就是去年习主席讲国际社会发展的今天已经成为一部复杂精巧、有机一体的机器，拆掉一个零部件就会使整个机器运转面临严重困难，被拆的人会受损，拆的人也会受损。',\n  '那么战后到现在 77 年已经形成了世界经济的金融格局。',\n  '地缘政治经济的基本国籍和世界各国认同的秩序、国际规则和国际经济运行的这些制度性安排。',\n  '那么全球的投资贸易布局、产业链、供应链布局、互联网、物联网、空中导航系统、人工智能下一代数字基础设施和高科技的运动发展都是为了互联，都是为了造福于人类。'],\n ['那么都是，它的背自然结果都会是全球的经济，社会联系越来越紧密，而不是脱钩分裂对抗阻断重构。',\n  '那么如果如果现在执意要推动这些这个一些政客出于去中国化也好，孤立其他国家也好。',\n  '那么这些行为我觉得最后会受到反噬。',\n  '那么建立全球化不仅会遭遇逆流，而且这一些阻断经济全球化的遏制经济全球化的对冲经济全球化的这一系列的行为。',\n  '也不管什么团体，也不管什么名头，我觉得最后都会受到历史的惩罚和抛弃。',\n  '谢谢。']]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_context[238][\"context\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T15:36:05.252673Z",
     "start_time": "2024-05-20T15:36:05.245162Z"
    }
   },
   "id": "45a514aa9f20c3da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[\"\".join(c) for c in data_context[0][\"context\"][i]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fe8445355037312"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "44"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_context[0][\"context\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T15:21:57.975469Z",
     "start_time": "2024-05-20T15:21:57.967226Z"
    }
   },
   "id": "520da627b88e758a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(215, 138, 17480)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_val = 0\n",
    "count = 0\n",
    "num = 0\n",
    "for i in range(len(data_context)):\n",
    "    for context in data_context[i][\"context\"]:\n",
    "        num +=1\n",
    "        val = len(context)\n",
    "        if val > 15:\n",
    "            count += 1\n",
    "        max_val = max(max_val,val)\n",
    "max_val,count,num"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T15:30:33.910776Z",
     "start_time": "2024-05-20T15:30:33.907820Z"
    }
   },
   "id": "bff5823285219085"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "lines=[]\n",
    "with open('/Users/dingyi/Downloads/CityU/Project/MeetingSummarization/TopicSegmentation/data/5/sg_5_short_test.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "data_context = [json.loads(line.rstrip('\\n')) for line in lines]\n",
    "# context_list = [d[\"context\"] for d in data_context]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T07:16:56.663070Z",
     "start_time": "2024-05-21T07:16:56.650726Z"
    }
   },
   "id": "a1a9e9c5d3819b71"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "example = data_context[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T07:16:57.702588Z",
     "start_time": "2024-05-21T07:16:57.696301Z"
    }
   },
   "id": "79261919417b595a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['好下各位下午好。', '临时科技我们是一家做安全的公司，可能跟各位的还有点不太一样。', '然后我们主要是给各种交易所，然后公链合约还有钱包等做安全审计的，包括今天的嘉宾，雷神公链，还有科特米尔公链都是我们的合作伙伴。', '然后大家可能只需要记，就是说后续有项目方或者交易所需要做安全审计的，比如说合约审计的或者是用户数字资产丢失了，有什么安全响应的事件可以找我们，我们是要做安全的企业。', '谢谢。']\n",
      "['好下各位下午好。', '临时科技我们是一家做安全的公司，可能跟各位的还有点不太一样。', '然后我们主要是给各种交易所，然后公链合约还有钱包等做安全审计的，包括今天的嘉宾，雷神公链，还有科特米尔公链都是我们的合作伙伴。', '然后大家可能只需要记，就是说后续有项目方或者交易所需要做安全审计的，比如说合约审计的或者是用户数字资产丢失了，有什么安全响应的事件可以找我们，我们是要做安全的企业。', '谢谢。']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(example[\"context\"])):\n",
    "    print(i)\n",
    "    print(example[\"context\"][i])\n",
    "    if example[\"context\"][i] is not None and example[\"eos_pos\"][i] is not None:\n",
    "        print([\"\".join(c) for c in example[\"context\"][i]])\n",
    "        break\n",
    "    break\n",
    "            # text_outputs = tokenizer(\n",
    "            #     [\"\".join(c) for c in example[\"context\"][i]],\n",
    "            #     add_special_tokens=False,\n",
    "            #     truncation=False,\n",
    "            # )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T07:19:35.390023Z",
     "start_time": "2024-05-21T07:19:35.384601Z"
    }
   },
   "id": "7308ba1fff2066f5"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/test/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    BertTokenizerFast,\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T07:16:20.114935Z",
     "start_time": "2024-05-21T07:16:18.577198Z"
    }
   },
   "id": "4f8c7d571a7acf79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_function(example, tokenizer, max_length=256):\n",
    "\n",
    "    inputs, attention_mask, position_ids, token_type_ids = [], [], [], []\n",
    "    eos_ids, eos_attention_mask = [], []\n",
    "    labels = []\n",
    "    for i in range(len(example[\"context\"])):\n",
    "        if example[\"context\"][i] is not None and example[\"eos_pos\"][i] is not None:\n",
    "            text_outputs = tokenizer(\n",
    "                [\"\".join(c) for c in example[\"context\"][i]],\n",
    "                add_special_tokens=False,\n",
    "                truncation=False,\n",
    "            )\n",
    "            text_input_ids = text_outputs[\"input_ids\"]\n",
    "            _tmp_input_ids, _tmp_position_ids, _tmp_eos_pos_ids, _tmp_token_type_ids = [], [], [], []\n",
    "            input_ids_length = []\n",
    "            for idx, text in enumerate(text_input_ids):\n",
    "                if len(text) > max_length:\n",
    "                    # text = text[:int(max_length//2)] + text[-int(max_length//2):]\n",
    "                    text = text[-int(max_length-1):]\n",
    "                text.insert(0, tokenizer.cls_token_id)\n",
    "                _tmp_input_ids.extend(text)\n",
    "                _tmp_token_type_ids.extend([idx % 2] * len(text))\n",
    "                input_ids_length.append(len(text))\n",
    "            total_length = sum(input_ids_length)\n",
    "            _tmp_attention_mask = [1] * total_length\n",
    "            acc_len = 0\n",
    "            for cur_len in input_ids_length:\n",
    "                # _tmp_mask = [0] * acc_len + [1] * cur_len + [0] * (total_length - acc_len - cur_len)\n",
    "                # _tmp_mask = [1] * total_length\n",
    "                # _tmp_attention_mask.extend([_tmp_mask] * cur_len)\n",
    "                _tmp_position_ids.extend(list(range(acc_len, acc_len + cur_len)))\n",
    "                acc_len += cur_len\n",
    "                _tmp_eos_pos_ids.append(acc_len - 1)\n",
    "            attention_mask.append(_tmp_attention_mask)\n",
    "            inputs.append(_tmp_input_ids)\n",
    "            position_ids.append(_tmp_position_ids)\n",
    "            eos_ids.append(_tmp_eos_pos_ids)\n",
    "            token_type_ids.append(_tmp_token_type_ids)\n",
    "            utt_num = len(example[\"context\"][i])\n",
    "            eos_attention_mask.append([1 for _ in range(utt_num)])\n",
    "            labels.append([int(_ in example[\"eos_pos\"][i]) for _ in range(utt_num)])\n",
    "\n",
    "    model_inputs = {\n",
    "        \"input_ids\": inputs,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"position_ids\": position_ids,\n",
    "        \"token_type_ids\": token_type_ids,\n",
    "        \"eos_ids\": eos_ids,\n",
    "        \"eos_attention_mask\": eos_attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "    return model_inputs\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "430dcbfda5658665"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "test",
   "language": "python",
   "display_name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
